{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install pinecone\n",
    "! pip unstall openai\n",
    "! pip install python-dotenv\n",
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef71fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06155522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec6b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,model_name,messages,temperature=0):\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=input_messages,\n",
    "        temperature=temperature,\n",
    "        top_p=0.8,\n",
    "        max_tokens=2000,\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4081d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "            api_key=os.getenv(\"RUNPOD_TOKEN\"),\n",
    "            base_url=os.getenv(\"RUNPOD_CHATBOT_URL\"),\n",
    "        )\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc0c58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e3a05040d427e8123bf5e82a95993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n403 Client Error. (Request ID: Root=1-681f97da-2ee9c6f62c949c6b739256f5;807792ca-dc3f-4d14-9e7d-217bca6da95f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     hf_hub_download(\n\u001b[0;32m    425\u001b[0m         path_or_repo_id,\n\u001b[0;32m    426\u001b[0m         filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    427\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    428\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    429\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    430\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    431\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    432\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    433\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    434\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    435\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    436\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    437\u001b[0m     )\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m   1009\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m   1013\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m   1014\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m   1015\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m   1018\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m   1019\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m   1020\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1021\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1024\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   1025\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1115\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1643\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1639\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1640\u001b[0m ):\n\u001b[0;32m   1641\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1531\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1531\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1532\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[0;32m   1533\u001b[0m     )\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1448\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1449\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1450\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1451\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m   1452\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1453\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1454\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1455\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1456\u001b[0m )\n\u001b[0;32m   1457\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    287\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    288\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    289\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[1;32m--> 310\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:426\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    423\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m     )\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-681f97da-2ee9c6f62c949c6b739256f5;807792ca-dc3f-4d14-9e7d-217bca6da95f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m login(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGING_FACE_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      8\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m pipe(messages)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:851\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    848\u001b[0m                 adapter_path \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    849\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 851\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    852\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    853\u001b[0m     )\n\u001b[0;32m    854\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    856\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1114\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1112\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1114\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1115\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1116\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:590\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    588\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 649\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    650\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    651\u001b[0m         configuration_file,\n\u001b[0;32m    652\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    653\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    654\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    655\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    656\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    657\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    658\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    659\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    660\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    661\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    662\u001b[0m     )\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:481\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    484\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n403 Client Error. (Request ID: Root=1-681f97da-2ee9c6f62c949c6b739256f5;807792ca-dc3f-4d14-9e7d-217bca6da95f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HUGGING_FACE_TOKEN\"))\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41ae661",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "404 page not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      2\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m      3\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the capital of Italy?\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[0;32m      4\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m      5\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m      6\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    706\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    707\u001b[0m             {\n\u001b[0;32m    708\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    709\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    710\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    711\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    712\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    713\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    714\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    715\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    716\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    717\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    718\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    719\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    724\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    725\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    726\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    727\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    728\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    729\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    730\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    731\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    732\u001b[0m             },\n\u001b[0;32m    733\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    734\u001b[0m         ),\n\u001b[0;32m    735\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    736\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    737\u001b[0m         ),\n\u001b[0;32m    738\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    739\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    740\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    741\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    948\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    949\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    950\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    951\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    952\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    953\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1050\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1054\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1055\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1060\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: 404 page not found"
     ]
    }
   ],
   "source": [
    "client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{'role':'user','content':\"What's the capital of Italy?\"}],\n",
    "        temperature=0.0,\n",
    "        top_p=0.8,\n",
    "        max_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169aee36",
   "metadata": {},
   "source": [
    "# Get LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba7753a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "404 page not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the capital of Italy?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m get_chatbot_response(client,model_name,messages)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_chatbot_response\u001b[1;34m(client, model_name, messages, temperature)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[0;32m      4\u001b[0m     input_messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m      8\u001b[0m     messages\u001b[38;5;241m=\u001b[39minput_messages,\n\u001b[0;32m      9\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m     10\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m     11\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,\n\u001b[0;32m     12\u001b[0m )\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    706\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    707\u001b[0m             {\n\u001b[0;32m    708\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    709\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    710\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    711\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    712\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    713\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    714\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    715\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    716\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    717\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    718\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    719\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    724\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    725\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    726\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    727\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    728\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    729\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    730\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    731\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    732\u001b[0m             },\n\u001b[0;32m    733\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    734\u001b[0m         ),\n\u001b[0;32m    735\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    736\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    737\u001b[0m         ),\n\u001b[0;32m    738\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    739\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    740\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    741\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    948\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    949\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    950\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    951\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    952\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    953\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Evrard\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1050\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1054\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1055\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1060\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: 404 page not found"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':\"What's the capital of Italy?\"}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac71a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d180eeb4",
   "metadata": {},
   "source": [
    "# Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1db3e",
   "metadata": {},
   "source": [
    "## Structred output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50ca843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answer questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    country: the country that you will get the capital of \n",
    "    capital: the capital of the country stated\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':\"What's the capital of Italy?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71161a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e9575d",
   "metadata": {},
   "source": [
    "## input structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "779e3f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"France\",\n",
      "    \"capital\": \"Paris\"\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Germany\",\n",
      "    \"capital\": \"Berlin\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. France\n",
    "3. Germany\n",
    "``\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':user_prompt})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c2718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'},\n",
       " {'country': 'France', 'capital': 'Paris'},\n",
       " {'country': 'Germany', 'capital': 'Berlin'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21aefb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08ffda13",
   "metadata": {},
   "source": [
    "## Give the model time to think (Chain of thought)\n",
    "\n",
    "> https://arxiv.org/pdf/2205.11916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0019ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca28fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cce70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bd98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91f7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1431449.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6243f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2681649.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 1431449.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69998a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58c5128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    steps: This is where you solve the equation bit by bit following the BEDMAS order of operations. You need to show your work and calculate each step leading to final result. Feel free to write here in free text. \n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4fb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"steps\": \"First, we need to follow the BEDMAS order of operations. \n",
      "    1. Divide 259 by 2: 259/2 = 129.5\n",
      "    2. Multiply 129.5 by 8654: 129.5 * 8654 = 1121011\n",
      "    3. Multiply 91072 by 33: 91072 * 33 = 3005016\n",
      "    4. Add 1121011 and 3005016: 1121011 + 3005016 = 4126027\n",
      "    5. Subtract 12971 from 4126027: 4126027 - 12971 = 4113056\",\n",
      "    \"result\": 4113056\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66cf1d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 4113056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aab814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e6b197",
   "metadata": {},
   "source": [
    "# RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1472c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b93c481",
   "metadata": {},
   "source": [
    "#### Asking about a subject that the LLM does not know anything about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05eefa05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since I'm not aware of any official information about the iPhone 16, I'll provide you with some general information about the latest iPhone models and some rumored features that might be included in future iPhone models.\n",
      "\n",
      "However, I can tell you about the latest iPhone models, such as the iPhone 14 series, which includes:\n",
      "\n",
      "1. iPhone 14\n",
      "2. iPhone 14 Plus\n",
      "3. iPhone 14 Pro\n",
      "4. iPhone 14 Pro Max\n",
      "\n",
      "Some of the key features of the iPhone 14 series include:\n",
      "\n",
      "1. Improved cameras with a new 48MP main camera on the Pro models\n",
      "2. Faster A16 Bionic chip\n",
      "3. Longer battery life\n",
      "4. New colors and designs\n",
      "5. Enhanced display with a higher refresh rate\n",
      "\n",
      "As for the iPhone 16, there's no official information available yet. However, based on rumors and leaks, here are some potential features that might be included:\n",
      "\n",
      "1. Improved cameras with a new periscope lens or a 3D modeling camera\n",
      "2. Faster A17 Bionic chip or a new chip design\n",
      "3. Enhanced display with a higher refresh rate or a new OLED panel\n",
      "4. New colors and designs\n",
      "5. Improved battery life and charging capabilities\n",
      "6. Enhanced biometric security with a new fingerprint sensor or facial recognition system\n",
      "7. Integration with augmented reality (AR) and virtual reality (VR) technologies\n",
      "8. Improved water and dust resistance\n",
      "9. Enhanced wireless charging capabilities\n",
      "10. New software features and updates to iOS\n",
      "\n",
      "Please note that these are just rumors and speculations, and Apple has not officially confirmed any of these features. I recommend checking Apple's official website or reputable tech news sources for the latest information on upcoming iPhone models.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f45f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e132c1",
   "metadata": {},
   "source": [
    "#### Giving Context to the unknown subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e753f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Appleâ€™s \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31f5e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger display sizes:\n",
      "   - Base model: 6.1-inch\n",
      "   - iPhone 16 Plus: 6.7-inch\n",
      "   - iPhone 16 Pro: 6.3-inch\n",
      "   - iPhone 16 Pro Max: 6.9-inch\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "\n",
      "3. New A18 chip (A18 Pro for Pro models) for improved performance, with:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix\" for refined audio capture during video recording\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max.\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "\n",
      "8. Support for up to 2x faster video encoding in Pro models.\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: $799\n",
      "   - Pro models: $999\n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902232f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546d94c8",
   "metadata": {},
   "source": [
    "#### Automatically extract context data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b0e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_s23 = \"\"\"\n",
    "The Samsung Galaxy S23 brings some incremental but notable upgrades to its predecessor, the Galaxy S22. It features the Snapdragon 8 Gen 2 processor, a powerful chip optimized for the S23 series, delivering enhanced performance, especially for gaming and multitasking. This chip ensures top-tier speed and efficiency across all models, from the base S23 to the larger S23+ and S23 Ultraâ€‹\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "In terms of design, the S23's camera module has been streamlined by removing the raised metal contour around the cameras, creating a cleaner, sleeker look. It also sports the same 6.1-inch 120Hz AMOLED display, protected by tougher Gorilla Glass Victus 2, making it more resistant to scratches and dropsâ€‹\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "The S23 Ultra stands out with its 200MP main camera, offering impressive photo clarity, especially in low-light conditions. The selfie camera across the series has been updated to a 12MP sensor, resulting in sharper selfies. The Ultra model also includes productivity tools such as the S-Pen, which remains an essential feature for note-taking and creative tasksâ€‹\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "Battery life is solid, with the S23 Ultra featuring a 5000mAh battery that lasts comfortably through a day of heavy use. However, charging speeds still lag behind some competitors, with 45W wired charging, which is slower than other brands offering up to 125W chargingâ€‹\n",
    "STUFF\n",
    ".\n",
    "\n",
    "Overall, the Galaxy S23 series enhances performance, durability, and camera quality, making it a strong contender for users seeking a high-performance flagship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510711ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [iphone_16,samsung_s23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b9efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What's new in iphone 16?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f90a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a12f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(\n",
    "        api_key=os.getenv(\"RUNPOD_TOKEN\"), \n",
    "        base_url=os.getenv(\"RUNPOD_EMBEDDING_URL\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b3fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_client,model_name,text_input):\n",
    "    output = embedding_client.embeddings.create(input = text_input,model=model_name)\n",
    "    \n",
    "    embedings = []\n",
    "    for embedding_object in output.data:\n",
    "        embedings.append(embedding_object.embedding)\n",
    "\n",
    "    return embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d06859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embeddings = get_embedding(embedding_client,model_name,user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb94816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.05110831558704376,\n",
       "  -0.03489653766155243,\n",
       "  0.06350376456975937,\n",
       "  -0.008884420618414879,\n",
       "  -0.03724740073084831,\n",
       "  -0.042040713131427765,\n",
       "  0.015921736136078835,\n",
       "  0.031126001849770546,\n",
       "  -0.01283814013004303,\n",
       "  0.04246814176440239,\n",
       "  0.05556579306721687,\n",
       "  0.01331899780780077,\n",
       "  -0.07211340963840485,\n",
       "  0.0014378030318766832,\n",
       "  0.09635474532842636,\n",
       "  0.028714081272482872,\n",
       "  0.11510057002305984,\n",
       "  -0.14752411842346191,\n",
       "  -0.07907439768314362,\n",
       "  0.016150716692209244,\n",
       "  -0.0367589071393013,\n",
       "  -0.014563122764229774,\n",
       "  -0.03975091129541397,\n",
       "  -0.030057430267333984,\n",
       "  0.030118491500616074,\n",
       "  0.06139714643359184,\n",
       "  0.0010905168019235134,\n",
       "  -0.012731282971799374,\n",
       "  -0.019188515841960907,\n",
       "  -0.1384870558977127,\n",
       "  -0.00042075058445334435,\n",
       "  -0.006739642005413771,\n",
       "  0.0166850034147501,\n",
       "  0.026943303644657135,\n",
       "  0.000493737927172333,\n",
       "  -0.03840756416320801,\n",
       "  -0.0031103105284273624,\n",
       "  0.03489653766155243,\n",
       "  -0.009601891040802002,\n",
       "  0.06374800950288773,\n",
       "  0.029599469155073166,\n",
       "  0.09122559428215027,\n",
       "  -0.10142283886671066,\n",
       "  -0.02421080879867077,\n",
       "  0.046742431819438934,\n",
       "  0.005743579473346472,\n",
       "  0.02724860981106758,\n",
       "  -0.019982313737273216,\n",
       "  0.011662710458040237,\n",
       "  -0.042712386697530746,\n",
       "  0.04546014592051506,\n",
       "  -0.0022459113970398903,\n",
       "  0.014685245230793953,\n",
       "  -0.05455828085541725,\n",
       "  -0.007789133582264185,\n",
       "  -0.016303369775414467,\n",
       "  0.007953235879540443,\n",
       "  0.031416043639183044,\n",
       "  0.06869397312402725,\n",
       "  0.04265132546424866,\n",
       "  0.08859995752573013,\n",
       "  -0.02335595153272152,\n",
       "  -0.1447153091430664,\n",
       "  0.09659899026155472,\n",
       "  0.009311850182712078,\n",
       "  0.03681996837258339,\n",
       "  -0.04552120715379715,\n",
       "  -0.1142457127571106,\n",
       "  0.023707052692770958,\n",
       "  -0.0735178142786026,\n",
       "  -0.0056825182400643826,\n",
       "  0.03630094975233078,\n",
       "  0.04533802345395088,\n",
       "  0.06231306865811348,\n",
       "  -0.01633390039205551,\n",
       "  -0.007953235879540443,\n",
       "  0.07498329132795334,\n",
       "  0.02607318013906479,\n",
       "  -0.041704874485731125,\n",
       "  0.034469109028577805,\n",
       "  0.0684497281908989,\n",
       "  0.0087622981518507,\n",
       "  0.02092876471579075,\n",
       "  0.028744611889123917,\n",
       "  0.030561186373233795,\n",
       "  -0.04234601929783821,\n",
       "  -0.038193847984075546,\n",
       "  0.028881998732686043,\n",
       "  0.001000832999125123,\n",
       "  -0.08359293639659882,\n",
       "  0.003173280041664839,\n",
       "  -0.021921010687947273,\n",
       "  0.06344269961118698,\n",
       "  0.0452464297413826,\n",
       "  -0.11241386830806732,\n",
       "  0.05959583818912506,\n",
       "  0.025035137310624123,\n",
       "  -0.058893632143735886,\n",
       "  -0.0548635870218277,\n",
       "  0.30726051330566406,\n",
       "  -0.01837945356965065,\n",
       "  0.035598743706941605,\n",
       "  0.058557797223329544,\n",
       "  -0.03935401514172554,\n",
       "  0.03419433534145355,\n",
       "  -0.050925131887197495,\n",
       "  -0.019142720848321915,\n",
       "  -0.0373084619641304,\n",
       "  -0.045826513320207596,\n",
       "  0.05721444636583328,\n",
       "  -0.007689908612519503,\n",
       "  -0.04100266844034195,\n",
       "  0.06032857298851013,\n",
       "  0.007613582070916891,\n",
       "  -0.003907924052327871,\n",
       "  -0.04026993364095688,\n",
       "  0.05254325643181801,\n",
       "  0.050864070653915405,\n",
       "  0.05263485014438629,\n",
       "  0.05043664202094078,\n",
       "  0.01057123951613903,\n",
       "  0.017494065687060356,\n",
       "  -0.0074952756986021996,\n",
       "  0.016837656497955322,\n",
       "  -0.0015732827596366405,\n",
       "  -0.025233587250113487,\n",
       "  0.0023985644802451134,\n",
       "  0.03608723357319832,\n",
       "  -0.031126001849770546,\n",
       "  0.021295132115483284,\n",
       "  0.009075237438082695,\n",
       "  0.010975770652294159,\n",
       "  -0.08853890001773834,\n",
       "  0.05568791553378105,\n",
       "  0.036270417273044586,\n",
       "  -0.02494354546070099,\n",
       "  0.003381269983947277,\n",
       "  -0.015326389111578465,\n",
       "  0.020898234099149704,\n",
       "  0.006690029986202717,\n",
       "  -0.07809741795063019,\n",
       "  -0.027889752760529518,\n",
       "  0.0882335901260376,\n",
       "  -0.07791423052549362,\n",
       "  0.012021445669233799,\n",
       "  0.034682825207710266,\n",
       "  -0.0001400116743752733,\n",
       "  0.05141362175345421,\n",
       "  -0.000184138014446944,\n",
       "  0.04054471105337143,\n",
       "  -0.03217931091785431,\n",
       "  0.08389823883771896,\n",
       "  0.0333700068295002,\n",
       "  0.016608675941824913,\n",
       "  0.01950908824801445,\n",
       "  0.01312054879963398,\n",
       "  -0.01883741468191147,\n",
       "  -0.038987647742033005,\n",
       "  -0.01917325146496296,\n",
       "  0.08188321441411972,\n",
       "  -0.007968501187860966,\n",
       "  0.007609765976667404,\n",
       "  -0.06258784234523773,\n",
       "  -0.019753333181142807,\n",
       "  -0.011105525307357311,\n",
       "  -0.17097166180610657,\n",
       "  0.007548704277724028,\n",
       "  0.051199909299612045,\n",
       "  -0.04716986045241356,\n",
       "  -0.0004651154449675232,\n",
       "  -0.010166708379983902,\n",
       "  -0.006445784587413073,\n",
       "  0.024042891338467598,\n",
       "  -0.03069857321679592,\n",
       "  0.06716743856668472,\n",
       "  -0.029492612928152084,\n",
       "  0.02657693438231945,\n",
       "  0.09421759843826294,\n",
       "  -0.006503029726445675,\n",
       "  -0.0057397629134356976,\n",
       "  -0.023004848510026932,\n",
       "  -0.029202571138739586,\n",
       "  -0.10093434900045395,\n",
       "  0.0508946031332016,\n",
       "  0.06124449521303177,\n",
       "  -0.02724860981106758,\n",
       "  0.016486553475260735,\n",
       "  -0.012960262596607208,\n",
       "  0.08347081393003464,\n",
       "  -0.015906471759080887,\n",
       "  0.025019871070981026,\n",
       "  0.030973348766565323,\n",
       "  -0.07321251183748245,\n",
       "  0.058832570910453796,\n",
       "  -0.03923189267516136,\n",
       "  -0.015799613669514656,\n",
       "  0.011303975246846676,\n",
       "  0.038926586508750916,\n",
       "  0.002831718185916543,\n",
       "  -0.05529101565480232,\n",
       "  0.014563122764229774,\n",
       "  -0.0067129279486835,\n",
       "  0.023936033248901367,\n",
       "  0.03398061916232109,\n",
       "  0.07205234467983246,\n",
       "  -0.004488006234169006,\n",
       "  0.0009807973401620984,\n",
       "  -0.049795497208833694,\n",
       "  0.03098861500620842,\n",
       "  0.01899006776511669,\n",
       "  -0.0006168146501295269,\n",
       "  0.01362430490553379,\n",
       "  0.1255420595407486,\n",
       "  -0.016440758481621742,\n",
       "  -0.0013261752901598811,\n",
       "  -0.07944076508283615,\n",
       "  -0.026668526232242584,\n",
       "  0.04054471105337143,\n",
       "  -0.0446663498878479,\n",
       "  -0.037735890597105026,\n",
       "  -0.004690271802246571,\n",
       "  0.05614587292075157,\n",
       "  0.025874730199575424,\n",
       "  -0.25816720724105835,\n",
       "  0.04231548681855202,\n",
       "  -0.008647807873785496,\n",
       "  -0.06722850352525711,\n",
       "  -0.00847988948225975,\n",
       "  -0.03437751904129982,\n",
       "  -0.0021581356413662434,\n",
       "  -0.04216283559799194,\n",
       "  0.06209935247898102,\n",
       "  0.040117282420396805,\n",
       "  -0.017723044380545616,\n",
       "  0.01382275391370058,\n",
       "  0.06380906701087952,\n",
       "  0.029843715950846672,\n",
       "  0.05648171156644821,\n",
       "  0.006758723873645067,\n",
       "  0.013983040116727352,\n",
       "  -0.06301527470350266,\n",
       "  0.03529343754053116,\n",
       "  0.009098134934902191,\n",
       "  -0.03697262331843376,\n",
       "  0.010250667110085487,\n",
       "  0.027462324127554893,\n",
       "  -0.014227285049855709,\n",
       "  -0.010258300229907036,\n",
       "  -0.09653793275356293,\n",
       "  0.05037558078765869,\n",
       "  0.005930579733103514,\n",
       "  0.012517568655312061,\n",
       "  0.013929611071944237,\n",
       "  0.040911078453063965,\n",
       "  0.053581301122903824,\n",
       "  -0.033339474350214005,\n",
       "  -0.12138988077640533,\n",
       "  -0.0020264722406864166,\n",
       "  0.03428592532873154,\n",
       "  0.03379743546247482,\n",
       "  0.06362588703632355,\n",
       "  -0.07638769596815109,\n",
       "  -0.09171408414840698,\n",
       "  0.001887176069431007,\n",
       "  0.025141993537545204,\n",
       "  0.04265132546424866,\n",
       "  -0.06490816920995712,\n",
       "  0.022027866914868355,\n",
       "  0.020028110593557358,\n",
       "  -0.016776595264673233,\n",
       "  0.038590747863054276,\n",
       "  -0.04527696222066879,\n",
       "  -0.027065426111221313,\n",
       "  0.04451369494199753,\n",
       "  -0.009479768574237823,\n",
       "  0.06722850352525711,\n",
       "  0.0220583975315094,\n",
       "  0.04759729281067848,\n",
       "  -0.0214935801923275,\n",
       "  -0.0548635870218277,\n",
       "  0.015738552436232567,\n",
       "  0.013715896755456924,\n",
       "  -0.0046635577455163,\n",
       "  -0.044361039996147156,\n",
       "  0.011540587991476059,\n",
       "  -0.06545772403478622,\n",
       "  -0.08115047961473465,\n",
       "  0.015860674902796745,\n",
       "  0.0015980890020728111,\n",
       "  -0.026317425072193146,\n",
       "  -0.1306712031364441,\n",
       "  -0.05648171156644821,\n",
       "  -0.12096245586872101,\n",
       "  -0.0008892053156159818,\n",
       "  0.002738218056038022,\n",
       "  -0.02973685786128044,\n",
       "  0.01599806360900402,\n",
       "  0.0226232148706913,\n",
       "  -0.02080664224922657,\n",
       "  0.0882335901260376,\n",
       "  0.029981102794408798,\n",
       "  0.03700315207242966,\n",
       "  -0.03623988851904869,\n",
       "  -0.006724376697093248,\n",
       "  0.11400146782398224,\n",
       "  0.03968985006213188,\n",
       "  -0.020821906626224518,\n",
       "  0.0007651745690964162,\n",
       "  0.04081948474049568,\n",
       "  0.0554131381213665,\n",
       "  -0.03086649253964424,\n",
       "  0.016929248347878456,\n",
       "  -0.03404168039560318,\n",
       "  -0.0023279625456780195,\n",
       "  -0.04146062955260277,\n",
       "  0.018700025975704193,\n",
       "  -0.08511946350336075,\n",
       "  0.06496923416852951,\n",
       "  -0.0087622981518507,\n",
       "  -0.15814879536628723,\n",
       "  -0.0008768022526055574,\n",
       "  0.021111948415637016,\n",
       "  0.013784591108560562,\n",
       "  -0.05874098092317581,\n",
       "  -0.024042891338467598,\n",
       "  0.026851711794734,\n",
       "  -0.017723044380545616,\n",
       "  -0.030011633411049843,\n",
       "  0.038590747863054276,\n",
       "  -0.04347565397620201,\n",
       "  -0.03636201098561287,\n",
       "  0.005171129480004311,\n",
       "  -0.021982071921229362,\n",
       "  -0.010388055816292763,\n",
       "  0.02414974756538868,\n",
       "  0.08206640183925629,\n",
       "  0.00922025740146637,\n",
       "  0.01410516258329153,\n",
       "  0.010380422696471214,\n",
       "  -0.024470319971442223,\n",
       "  -0.029492612928152084,\n",
       "  0.059626370668411255,\n",
       "  -0.07131960988044739,\n",
       "  -0.03069857321679592,\n",
       "  0.028851468116044998,\n",
       "  0.02567628026008606,\n",
       "  0.023279624059796333,\n",
       "  -0.0063923560082912445,\n",
       "  0.033553190529346466,\n",
       "  0.02160043828189373,\n",
       "  0.007186152972280979,\n",
       "  0.05434456467628479,\n",
       "  0.027569182217121124,\n",
       "  -0.023142237216234207,\n",
       "  -0.010357524268329144,\n",
       "  -0.04970390722155571,\n",
       "  -0.032209839671850204,\n",
       "  -0.030057430267333984,\n",
       "  0.02781342715024948,\n",
       "  -0.053398117423057556,\n",
       "  0.003934638109058142,\n",
       "  -0.1311596930027008,\n",
       "  0.019371701404452324,\n",
       "  0.0633205771446228,\n",
       "  -0.05077248066663742,\n",
       "  -0.04646765813231468,\n",
       "  0.03343106806278229,\n",
       "  -0.033400535583496094,\n",
       "  -0.010502545163035393,\n",
       "  -0.00972401350736618,\n",
       "  -0.039384543895721436,\n",
       "  0.0003277274954598397,\n",
       "  0.030347470194101334,\n",
       "  0.053398117423057556,\n",
       "  -0.00101419014390558,\n",
       "  -0.012906834483146667,\n",
       "  -0.04420838877558708,\n",
       "  0.033675312995910645,\n",
       "  0.04054471105337143,\n",
       "  0.026332689449191093,\n",
       "  0.006018355488777161,\n",
       "  -0.05605428293347359,\n",
       "  0.0163949616253376,\n",
       "  -0.013593774288892746]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b6797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embeddings = user_prompt_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5c89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929b2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embeddings = [get_embedding(embedding_client,model_name,x)[0] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c1c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similaraty_scores = cosine_similarity([user_prompt_embeddings], data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee652d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73779758, 0.52622817]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similaraty_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06a7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_entry_index=data_similaraty_scores.argmax()\n",
    "closest_entry_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5247a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Appleâ€™s \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[closest_entry_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47352cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e1943cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_with_data = f\"\"\"\n",
    "{data[closest_entry_index]}\n",
    "\n",
    "{user_prompt}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d7473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Appleâ€™s \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n\\n\\nWhat\\'s new in iphone 16?\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969633a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger display sizes:\n",
      "   - Base model: 6.1-inch\n",
      "   - iPhone 16 Plus: 6.7-inch\n",
      "   - iPhone 16 Pro: 6.3-inch\n",
      "   - iPhone 16 Pro Max: 6.9-inch\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "\n",
      "3. New A18 chip (A18 Pro for Pro models) for improved performance, with:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix\" for refined audio capture during video recording\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max.\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "\n",
      "8. Support for up to 2x faster video encoding in Pro models.\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: $799\n",
      "   - Pro models: $999\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':user_prompt_with_data}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67627e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00890ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b598fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e59445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
